---
title: "Classification"
author: "Chang Xu"
output: html_notebook
---

```{r, include=FALSE}
knitr::opts_chunk$set(error = TRUE)
knitr::opts_chunk$set(cache = TRUE)
knitr::opts_chunk$set(message = FALSE)
knitr::opts_chunk$set(warning = FALSE)
options(mc.cores = parallel::detectCores())
library(dplyr)
library(tidyverse)
library(R.matlab)
library(caret)
library(pROC)
library(gam)
library(earth)
library(BART)
library(e1071)
library(EBImage)
library(ggplot2)
library(xgboost)
library(randomForest)
library(doMC)
library(glmnet)
```

## load data

```{r, eval = F}
train_dir <- "../train_set/" # This will be modified for different data sets.
train_image_dir <- paste(train_dir, "images/", sep="")
train_pt_dir <- paste(train_dir,  "points/", sep="")
train_label_path <- paste(train_dir, "label.csv", sep="") 

n_files <- length(list.files(train_image_dir))
image_list <- list()
for(i in 1:100){
   image_list[[i]] <- readImage(paste0(train_image_dir, sprintf("%04d", i), ".jpg"))
}

#function to read fiducial points
#input: index
#output: matrix of fiducial points corresponding to the index
readMat.matrix <- function(index){
     return(round(readMat(paste0(train_pt_dir, sprintf("%04d", index), ".mat"))[[1]],0))
}

#load fiducial points
fiducial_pt_list <- lapply(1:n_files, readMat.matrix)
#save(fiducial_pt_list, file="fiducial_pt_list.RData")
```

```{r}
dat <- read.csv("dat_test.csv") 
# name <- function(x) {
#   x <- sub(" ", "type", x)
# }
# dat$emotion_idx <- name(dat$emotion_idx)
# dat$emotion_idx <- as.factor(dat$emotion_idx)

label <- read.csv("label.csv")
```
```{r}
labels <- select(label, "X", "emotion_cat")
```

```{r}
mydata <- dat[ , -6008] %>% left_join(labels, by = "X")
mydata$emotion_cat <- factor(mydata$emotion_cat, 
                             levels = c("Neutral", "Happy", "Sad", "Angry", "Surprised"))
```

## split dataset & k-fold CV
```{r}
set.seed(2121)
in_train <- createDataPartition(y = mydata$emotion_cat, p = 4 / 5, list = FALSE)
training <- mydata[ in_train, ]
testing  <- mydata[-in_train, ]
ctrl <- trainControl(method = "cv", number = 10, classProbs = T)
```

#Lasso
```{r}
#ctrl1 <- trainControl(method = "repeatedcv", repeats = 3, 
                     #classProbs = TRUE)
enetGrid <- expand.grid(.lambda = seq(.05, 1, length = 10),
                        .fraction = seq(.05, 1, length = 10))
lasso <- train(emotion_cat ~ ., data = training, method = "glmnet", 
               trControl = ctrl, tuneGrid = enetGrid, 
               preProcess = c("center", "scale"))

z <- predict(lasso, newdata = testing) 
defaultSummary(data.frame(obs = testing$emotion_cat, pred = z))
```

lasso$bestTune

```{r}
lambda <- lasso$bestTune$lambda
b_lasso <- coef(predict(lasso$finalModel, type = "coefficients", 
                        s = lambda, mode = "penalty"))
```
```{r}
y_hat <- predict(lasso, newdata = testing)
confusionMatrix(y_hat, reference = testing$emotion_idx)

```


## random forest
```{r}
rf_grid <- data.frame(.mtry = 2:(ncol(training) - 1L))
out <- train(emotion_cat ~ ., data = training, method = "rf",
             trControl = ctrl, tuneGrid = rf_grid, 
             ntrees = 128, importance = TRUE)
#varImp(out)
y_hat <- predict(out, newdata = testing)
confusionMatrix(y_hat, reference = testing$emotion_cat)

```

```{r}

```


## BART

```{r}
X_train <- model.matrix(emotion_cat ~ ., data = training)
X_test <- model.matrix(emotion_cat ~ ., data = testing)
bart <- mc.wbart(X_train, y = training$emotion_idx, X_test,
                mc.cores = parallel::detectCores())
confusionMatrix(predict(bart, newdata = testing), reference = testing$emotion_cat)
#defaultSummary(data.frame(obs = testing$emotion_cat, pred = exp(bart$yhat.test.mean)))
```

## LDA
```{r}
LDA <- train(emotion_cat ~ ., data = training, method = "lda", 
             preProcess = c("center", "scale"))
confusionMatrix(predict(LDA, newdata = testing), reference = testing$emotion_cat)
```


## QDA
```{r}
QDA <- train(emotion_cat ~ ., data = training, method = "qda", 
             preProcess = c("center", "scale"))
confusionMatrix(predict(QDA, newdata = testing), reference = testing$emotion_cat)
```


## PLSDA
```{r}
PLSDA_grid <- expand.grid(.ncomp = 1:7)
PLSDA <- train(emotion_cat ~ ., data = training, method = "pls", 
               preProcess = c("center", "scale"),
               trControl = ctrl, tuneGrid = PLSDA_grid)
confusionMatrix(predict(PLSDA, newdata = testing), reference = testing$emotion_cat)
```


## NSC
```{r}
NSC <- train(emotion_cat ~ ., data = training, method = "pam", 
             preProcess = c("center", "scale"),
             trControl = ctrl, 
             tuneGrid = data.frame(.threshold = 0:25))
confusionMatrix(predict(NSC, newdata = testing), reference = testing$emotion_cat)
```


## SVM
```{r}

```



## NN
```{r}
nnetGrid <- expand.grid(.decay = c(0, 0.01, .1),
                        .size = c(1:10))
ctrl <- trainControl(method = "cv", number = 10)
nn <- train(emotion_cat ~ ., data = training, method = "nnet",
            trControl = ctrl, tuneGrid = nnetGrid,
            preProcess = c("center", "scale"), trace = FALSE)
defaultSummary(data.frame(obs = testing$emotion_cat,
                          pred = predict(nn, newdata = testing)))
```

## KNN
```{r}

```



## Bag of words
```{r}

```
