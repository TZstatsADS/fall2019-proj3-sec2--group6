{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from PIL import Image\n",
    "from skimage.transform import resize\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_factor = (188, 250)\n",
    "\n",
    "train_img_path = '../data/train_set/train_images/'\n",
    "test_img_path = '../data/train_set/test_images/'\n",
    "train_features_path = '../data/train_set/train_points/'\n",
    "test_features_path = '../data/train_set/test_points/'\n",
    "labels = pd.read_csv('../data/train_set/label.csv')\n",
    "\n",
    "train_img = sorted(os.listdir(train_img_path))\n",
    "test_img = sorted(os.listdir(test_img_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train emotion indexes\n",
    "train_indexes = []\n",
    "for img in train_img:\n",
    "    if img == \".DS_Store\":\n",
    "        continue\n",
    "    img = int(img[:4])\n",
    "    train_indexes.append(img - 1)\n",
    "    \n",
    "emotion_idx = labels[['emotion_idx']].loc[train_indexes].values[:, 0] - 1\n",
    "\n",
    "### Test emotion indexes\n",
    "test_indexes = []\n",
    "for img in test_img:\n",
    "    if img == \".DS_Store\":\n",
    "        continue\n",
    "    img = int(img[:4])\n",
    "    test_indexes.append(img - 1)\n",
    "    \n",
    "test_emotion_idx = labels[['emotion_idx']].loc[test_indexes].values[:, 0] - 1  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 77.71262311935425 seconds ---\n",
      "--- 20.534557104110718 seconds ---\n"
     ]
    }
   ],
   "source": [
    "imgs = []\n",
    "start_time = time.time()\n",
    "for img in train_img:\n",
    "    if img == '.DS_Store':\n",
    "        continue\n",
    "    img = np.asarray(Image.open(os.path.join(train_img_path, img)))\n",
    "    img = resize(img, resize_factor, anti_aliasing=False)\n",
    "    imgs.append(img)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))  \n",
    "\n",
    "imgs_test = []\n",
    "start_time = time.time()\n",
    "for img in test_img:\n",
    "    if img == '.DS_Store':\n",
    "        continue\n",
    "    img = np.asarray(Image.open(os.path.join('../data/train_set/test_images/', img)))\n",
    "    img = resize(img, resize_factor, anti_aliasing=False)\n",
    "    imgs_test.append(img)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time)) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 1999 samples, validate on 501 samples\n",
      "Epoch 1/10\n",
      "1999/1999 [==============================] - 481s 241ms/step - loss: 3.1356 - acc: 0.0445 - val_loss: 3.0912 - val_acc: 0.0579\n",
      "Epoch 2/10\n",
      "1999/1999 [==============================] - 490s 245ms/step - loss: 3.0909 - acc: 0.0415 - val_loss: 3.0911 - val_acc: 0.0559\n",
      "Epoch 3/10\n",
      " 768/1999 [==========>...................] - ETA: 4:32 - loss: 3.0926 - acc: 0.0573"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:Internal Python error in the inspect module.\n",
      "Below is the traceback from this internal error.\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 2963, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"<ipython-input-16-26618e42ffc2>\", line 13, in <module>\n",
      "    history = model.fit(np.array(imgs), emotion_idx, epochs=10, validation_data=(np.array(imgs_test), test_emotion_idx))\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training.py\", line 1363, in fit\n",
      "    validation_steps=validation_steps)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/engine/training_arrays.py\", line 264, in fit_loop\n",
      "    outs = f(ins_batch)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/keras/backend.py\", line 2914, in __call__\n",
      "    fetched = self._callable_fn(*array_vals)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\", line 1382, in __call__\n",
      "    run_metadata_ptr)\n",
      "KeyboardInterrupt\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py\", line 1863, in showtraceback\n",
      "    stb = value._render_traceback_()\n",
      "AttributeError: 'KeyboardInterrupt' object has no attribute '_render_traceback_'\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 1095, in get_records\n",
      "    return _fixed_getinnerframes(etb, number_of_lines_of_context, tb_offset)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/IPython/core/ultratb.py\", line 305, in wrapped\n",
      "    def wrapped(*args, **kwargs):\n",
      "KeyboardInterrupt\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:tornado.general:Uncaught exception in ZMQStream callback\n",
      "Traceback (most recent call last):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py\", line 432, in _run_callback\n",
      "    callback(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py\", line 276, in null_wrapper\n",
      "    return fn(*args, **kwargs)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 283, in dispatcher\n",
      "    return self.dispatch_shell(stream, msg)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 233, in dispatch_shell\n",
      "    handler(stream, idents, msg)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 421, in execute_request\n",
      "    self._abort_queues()\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 636, in _abort_queues\n",
      "    self._abort_queue(stream)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py\", line 642, in _abort_queue\n",
      "    idents,msg = self.session.recv(stream, zmq.NOBLOCK, content=True)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/jupyter_client/session.py\", line 815, in recv\n",
      "    return idents, self.deserialize(msg_list, content=content, copy=copy)\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/jupyter_client/session.py\", line 930, in deserialize\n",
      "    message['parent_header'] = extract_dates(self.unpack(msg_list[2]))\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/jupyter_client/jsonutil.py\", line 66, in extract_dates\n",
      "    for k,v in iteritems(obj):\n",
      "  File \"/anaconda3/lib/python3.6/site-packages/ipython_genutils/py3compat.py\", line 188, in iteritems\n",
      "    def iteritems(d): return iter(d.items())\n",
      "KeyboardInterrupt\n"
     ]
    }
   ],
   "source": [
    "model = models.Sequential()\n",
    "model.add(layers.Conv2D(128, (3, 3), activation='relu', input_shape=(188, 250, 3)))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu'))\n",
    "model.add(layers.Flatten())\n",
    "model.add(layers.Dense(32, activation='relu'))\n",
    "model.add(layers.Dense(22, activation='softmax'))\n",
    "\n",
    "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "history = model.fit(np.array(imgs), emotion_idx, epochs=10, validation_data=(np.array(imgs_test), test_emotion_idx))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (BMEN4000)",
   "language": "python",
   "name": "bmen4000"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
