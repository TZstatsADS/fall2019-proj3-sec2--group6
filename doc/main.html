<!DOCTYPE html>

<html xmlns="http://www.w3.org/1999/xhtml">

<head>

<meta charset="utf-8" />
<meta http-equiv="Content-Type" content="text/html; charset=utf-8" />
<meta name="generator" content="pandoc" />
<meta http-equiv="X-UA-Compatible" content="IE=EDGE" />




<title>main</title>

<script src="main-copy_files/jquery-1.11.3/jquery.min.js"></script>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<link href="main-copy_files/bootstrap-3.3.5/css/bootstrap.min.css" rel="stylesheet" />
<script src="main-copy_files/bootstrap-3.3.5/js/bootstrap.min.js"></script>
<script src="main-copy_files/bootstrap-3.3.5/shim/html5shiv.min.js"></script>
<script src="main-copy_files/bootstrap-3.3.5/shim/respond.min.js"></script>
<script src="main-copy_files/navigation-1.1/tabsets.js"></script>
<link href="main-copy_files/highlightjs-9.12.0/default.css" rel="stylesheet" />
<script src="main-copy_files/highlightjs-9.12.0/highlight.js"></script>

<style type="text/css">code{white-space: pre;}</style>
<style type="text/css">
  pre:not([class]) {
    background-color: white;
  }
</style>
<script type="text/javascript">
if (window.hljs) {
  hljs.configure({languages: []});
  hljs.initHighlightingOnLoad();
  if (document.readyState && document.readyState === "complete") {
    window.setTimeout(function() { hljs.initHighlighting(); }, 0);
  }
}
</script>



<style type="text/css">
h1 {
  font-size: 34px;
}
h1.title {
  font-size: 38px;
}
h2 {
  font-size: 30px;
}
h3 {
  font-size: 24px;
}
h4 {
  font-size: 18px;
}
h5 {
  font-size: 16px;
}
h6 {
  font-size: 12px;
}
.table th:not([align]) {
  text-align: left;
}
</style>




<style type = "text/css">
.main-container {
  max-width: 940px;
  margin-left: auto;
  margin-right: auto;
}
code {
  color: inherit;
  background-color: rgba(0, 0, 0, 0.04);
}
img {
  max-width:100%;
}
.tabbed-pane {
  padding-top: 12px;
}
.html-widget {
  margin-bottom: 20px;
}
button.code-folding-btn:focus {
  outline: none;
}
summary {
  display: list-item;
}
</style>



<!-- tabsets -->

<style type="text/css">
.tabset-dropdown > .nav-tabs {
  display: inline-table;
  max-height: 500px;
  min-height: 44px;
  overflow-y: auto;
  background: white;
  border: 1px solid #ddd;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs > li.active:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li.active:before {
  content: "&#xe258;";
  border: none;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open:before {
  content: "";
  font-family: 'Glyphicons Halflings';
  display: inline-block;
  padding: 10px;
  border-right: 1px solid #ddd;
}

.tabset-dropdown > .nav-tabs > li.active {
  display: block;
}

.tabset-dropdown > .nav-tabs > li > a,
.tabset-dropdown > .nav-tabs > li > a:focus,
.tabset-dropdown > .nav-tabs > li > a:hover {
  border: none;
  display: inline-block;
  border-radius: 4px;
}

.tabset-dropdown > .nav-tabs.nav-tabs-open > li {
  display: block;
  float: none;
}

.tabset-dropdown > .nav-tabs > li {
  display: none;
}
</style>

<!-- code folding -->




</head>

<body>


<div class="container-fluid main-container">




<div class="fluid-row" id="header">



<h1 class="title toc-ignore">main</h1>

</div>


<div id="install-and-load-packages-we-need" class="section level3">
<h3>Install and load packages we need</h3>
<pre class="r"><code>if(!require(&quot;EBImage&quot;)){
  source(&quot;https://bioconductor.org/biocLite.R&quot;)
  biocLite(&quot;EBImage&quot;)
}
if(!require(&quot;R.matlab&quot;)){
  install.packages(&quot;R.matlab&quot;)
}
if(!require(&quot;readxl&quot;)){
  install.packages(&quot;readxl&quot;)
}

if(!require(&quot;dplyr&quot;)){
  install.packages(&quot;dplyr&quot;)
}
if(!require(&quot;readxl&quot;)){
  install.packages(&quot;readxl&quot;)
}

if(!require(&quot;ggplot2&quot;)){
  install.packages(&quot;ggplot2&quot;)
}

if(!require(&quot;caret&quot;)){
  install.packages(&quot;caret&quot;)
}

library(R.matlab)
library(readxl)
library(dplyr)
library(EBImage)
library(ggplot2)
library(caret)</code></pre>
</div>
<div id="construct-features" class="section level3">
<h3>Construct features</h3>
</div>
<div id="step-0-set-work-directories-extract-paths-summarize" class="section level3">
<h3>Step 0 set work directories, extract paths, summarize</h3>
<pre class="r"><code>set.seed(0)
setwd(&quot;~/Desktop/proj3-sec2-group6/doc&quot;)
# here replace it with your own path or manually set it in RStudio to where this rmd file is located. 
# use relative path for reproducibility</code></pre>
<p>Provide directories for training images. Training images and Training fiducial points will be in different subfolders.</p>
<pre class="r"><code>train_dir &lt;- &quot;../data/train_set/&quot; # This will be modified for different data sets.
train_image_dir &lt;- paste(train_dir, &quot;images/&quot;, sep=&quot;&quot;)
train_pt_dir &lt;- paste(train_dir,  &quot;points/&quot;, sep=&quot;&quot;)
train_label_path &lt;- paste(train_dir, &quot;label.csv&quot;, sep=&quot;&quot;) </code></pre>
</div>
<div id="step-1-set-up-controls-for-evaluation-experiments." class="section level3">
<h3>Step 1: set up controls for evaluation experiments.</h3>
<p>In this chunk, we have a set of controls for the evaluation experiments.</p>
<ul>
<li>(T/F) cross-validation on the training set</li>
<li>(number) K, the number of CV folds</li>
<li>(T/F) process features for training set</li>
<li>(T/F) run evaluation on an independent test set</li>
<li>(T/F) process features for test set</li>
</ul>
<pre class="r"><code>run.cv=TRUE # run cross-validation on the training set
K &lt;- 5  # number of CV folds
run.feature.train=TRUE # process features for training set
run.test=TRUE # run evaluation on an independent test set
run.feature.test=TRUE # process features for test set</code></pre>
<p>Using cross-validation or independent test set evaluation, we compare the performance of models with different specifications. In this Starter Code, we tune parameter k (number of neighbours) for KNN.</p>
<pre class="r"><code>k = c(5,11,21,31,41,51)
model_labels = paste(&quot;KNN with K =&quot;, k)</code></pre>
</div>
<div id="step-2-import-data-and-train-test-split" class="section level3">
<h3>Step 2: import data and train-test split</h3>
<pre class="r"><code>#train-test split
info &lt;- read.csv(train_label_path)
n &lt;- nrow(info)
n_train &lt;- round(n*(4/5), 0)
train_idx &lt;- sample(info$Index, n_train, replace = F)
test_idx &lt;- setdiff(info$Index,train_idx)</code></pre>
<p>If you choose to extract features from images, such as using Gabor filter, R memory will exhaust all images are read together. The solution is to repeat reading a smaller batch(e.g 100) and process them.</p>
<pre class="r"><code>n_files &lt;- length(list.files(train_image_dir))

image_list &lt;- list()
for(i in 1:100){
   image_list[[i]] &lt;- readImage(paste0(train_image_dir, sprintf(&quot;%04d&quot;, i), &quot;.jpg&quot;))
}</code></pre>
<p>Fiducial points are stored in matlab format. In this step, we read them and store them in a list.</p>
<pre class="r"><code>#function to read fiducial points;If you want to process test data(without emotion_idx),use function:feature_test
#input: index
#output: matrix of fiducial points corresponding to the index
readMat.matrix &lt;- function(index){
     return(round(readMat(paste0(train_pt_dir, sprintf(&quot;%04d&quot;, index), &quot;.mat&quot;))[[1]],0))
}

#load fiducial points
fiducial_pt_list &lt;- lapply(1:n_files, readMat.matrix)
save(fiducial_pt_list, file=&quot;../output/fiducial_pt_list.RData&quot;)</code></pre>
</div>
<div id="step-3-construct-features-and-responses" class="section level3">
<h3>Step 3: construct features and responses</h3>
<ul>
<li><p>The follow plots show how pairwise distance between fiducial points can work as feature for facial emotion recognition.</p></li>
<li>In the first column, 78 fiducials points of each emotion are marked in order.</li>
<li>In the second column distributions of vertical distance between right pupil(1) and right brow peak(21) are shown in histograms. For example, the distance of an angry face tends to be shorter than that of a surprised face.</li>
<li><p>The third column is the distributions of vertical distances between right mouth corner(50) and the midpoint of the upper lip(52). For example, the distance of an happy face tends to be shorter than that of a face.</p></li>
</ul>
<div class="figure">
<img src="../figs/feature_visualization.jpg" alt="Figure1" />
<p class="caption">Figure1</p>
</div>
<p><code>feature.R</code> should be the wrapper for all your feature engineering functions and options. The function <code>feature( )</code> should have options that correspond to different scenarios for your project and produces an R object that contains features and responses that are required by all the models you are going to evaluate later.</p>
<ul>
<li><code>feature.R</code></li>
<li>Input: list of images or fiducial point</li>
<li>Output: an RData file that contains extracted features and corresponding responses</li>
</ul>
</div>
<div id="step-4-we-need-split-data-intro-training-and-testing-set" class="section level3">
<h3>Step 4: We need split data intro training and testing set</h3>
<pre class="r"><code>source(&quot;../lib/feature.R&quot;)
tm_feature_train &lt;- NA
if(run.feature.train){
  tm_feature_train &lt;- system.time(dat_train &lt;- feature(fiducial_pt_list, train_idx))
}

tm_feature_test &lt;- NA
if(run.feature.train){
  tm_feature_test &lt;- system.time(dat_test &lt;- feature(fiducial_pt_list, test_idx))
}

# summarizing time for feature construction
cat(&quot;Time for constructing training feature =&quot;, tm_feature_train[1], &quot;s \n&quot;)</code></pre>
<pre><code>## Time for constructing training feature = 0.84 s</code></pre>
<pre class="r"><code>cat(&quot;Time for constructing testing feature =&quot;, tm_feature_test[1], &quot;s \n&quot;)</code></pre>
<pre><code>## Time for constructing testing feature = 0.206 s</code></pre>
<pre class="r"><code>save(dat_train, file=&quot;../output/feature_train.RData&quot;)
save(dat_test, file=&quot;../output/feature_test.RData&quot;)</code></pre>
</div>
<div id="load-training-and-testing-rdata" class="section level3">
<h3>load training and testing Rdata</h3>
<pre class="r"><code>load(&quot;../output/feature_train.RData&quot;)
load(&quot;../output/feature_test.RData&quot;)</code></pre>
</div>
<div id="base-model" class="section level3">
<h3>base model</h3>
</div>
<div id="this-is-how-we-work-out-gbm-model-it-will-take-more-than-3-hours.-thus-i-saved-the-model." class="section level3">
<h3>This is how we work out gbm model, it will take more than 3 hours. Thus I saved the model.</h3>
<pre class="r"><code>fitControl &lt;- trainControl(
  method = &quot;repeatedcv&quot;,
  number = 5,
  repeats = 1)

gbmGrid &lt;- expand.grid(interaction.depth = 2,
                       n.trees = 300,
                       shrinkage = 0.15,
                       n.minobsinnode = 10)

tm_train_gbm&lt;-system.time(gbmFit_base &lt;- train(emotion_idx~., data = dat_train,
                method = &quot;gbm&quot;,
                trControl = fitControl,
                verbose = TRUE,
                tuneGrid = gbmGrid))</code></pre>
<pre><code>## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        3.0910             nan     0.1500    0.1113
##      2        2.6288             nan     0.1500    0.0852
##      3        2.4149             nan     0.1500    0.0655
##      4        2.2579             nan     0.1500    0.0077
##      5        2.1108             nan     0.1500    0.0512
##      6        1.9926             nan     0.1500   -0.0080
##      7        1.8970             nan     0.1500    0.0010
##      8        1.8063             nan     0.1500    0.0099
##      9        1.7182             nan     0.1500    0.0041
##     10        1.6368             nan     0.1500   -0.0098
##     20        1.0999             nan     0.1500   -0.0281
##     40        0.5842             nan     0.1500   -0.0072
##     60        0.3346             nan     0.1500   -0.0059
##     80        0.2054             nan     0.1500   -0.0042
##    100        0.1332             nan     0.1500   -0.0029
##    120        0.0883             nan     0.1500   -0.0019
##    140        0.0596             nan     0.1500   -0.0007
##    160        0.0408             nan     0.1500   -0.0008
##    180        0.0283             nan     0.1500   -0.0006
##    200        0.0197             nan     0.1500   -0.0004
##    220        0.0138             nan     0.1500   -0.0003
##    240        0.0099             nan     0.1500   -0.0002
##    260        0.0071             nan     0.1500   -0.0001
##    280        0.0050             nan     0.1500   -0.0001
##    300        0.0036             nan     0.1500   -0.0001
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        3.0910             nan     0.1500    0.1676
##      2        2.6402             nan     0.1500    0.1127
##      3        2.4031             nan     0.1500    0.0277
##      4        2.2400             nan     0.1500    0.0385
##      5        2.0983             nan     0.1500    0.0196
##      6        1.9733             nan     0.1500    0.0142
##      7        1.8539             nan     0.1500    0.0103
##      8        1.7688             nan     0.1500    0.0276
##      9        1.6796             nan     0.1500    0.0045
##     10        1.6035             nan     0.1500   -0.0046
##     20        1.0769             nan     0.1500   -0.0199
##     40        0.5604             nan     0.1500   -0.0064
##     60        0.3249             nan     0.1500   -0.0035
##     80        0.2011             nan     0.1500   -0.0041
##    100        0.1312             nan     0.1500   -0.0021
##    120        0.0882             nan     0.1500   -0.0014
##    140        0.0596             nan     0.1500   -0.0011
##    160        0.0408             nan     0.1500   -0.0008
##    180        0.0283             nan     0.1500   -0.0006
##    200        0.0198             nan     0.1500   -0.0004
##    220        0.0141             nan     0.1500   -0.0003
##    240        0.0099             nan     0.1500   -0.0003
##    260        0.0070             nan     0.1500   -0.0002
##    280        0.0050             nan     0.1500   -0.0001
##    300        0.0036             nan     0.1500   -0.0001
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        3.0910             nan     0.1500    0.1390
##      2        2.6383             nan     0.1500    0.1462
##      3        2.4111             nan     0.1500    0.0074
##      4        2.2672             nan     0.1500    0.0531
##      5        2.1160             nan     0.1500    0.0503
##      6        1.9841             nan     0.1500    0.0150
##      7        1.8727             nan     0.1500    0.0287
##      8        1.7789             nan     0.1500    0.0018
##      9        1.6948             nan     0.1500    0.0105
##     10        1.6098             nan     0.1500   -0.0131
##     20        1.0844             nan     0.1500   -0.0060
##     40        0.5730             nan     0.1500   -0.0075
##     60        0.3330             nan     0.1500   -0.0048
##     80        0.2052             nan     0.1500   -0.0012
##    100        0.1319             nan     0.1500   -0.0024
##    120        0.0881             nan     0.1500   -0.0016
##    140        0.0605             nan     0.1500   -0.0008
##    160        0.0416             nan     0.1500   -0.0007
##    180        0.0288             nan     0.1500   -0.0004
##    200        0.0202             nan     0.1500   -0.0004
##    220        0.0140             nan     0.1500   -0.0004
##    240        0.0098             nan     0.1500   -0.0002
##    260        0.0070             nan     0.1500   -0.0002
##    280        0.0050             nan     0.1500   -0.0001
##    300        0.0036             nan     0.1500   -0.0001
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        3.0910             nan     0.1500    0.0721
##      2        2.6540             nan     0.1500    0.1066
##      3        2.4689             nan     0.1500    0.0620
##      4        2.2940             nan     0.1500    0.0975
##      5        2.1152             nan     0.1500   -0.0013
##      6        1.9875             nan     0.1500   -0.0073
##      7        1.8890             nan     0.1500   -0.0086
##      8        1.8051             nan     0.1500   -0.0269
##      9        1.7233             nan     0.1500   -0.0003
##     10        1.6430             nan     0.1500   -0.0237
##     20        1.0946             nan     0.1500   -0.0047
##     40        0.5710             nan     0.1500   -0.0088
##     60        0.3321             nan     0.1500   -0.0069
##     80        0.2045             nan     0.1500   -0.0050
##    100        0.1335             nan     0.1500   -0.0022
##    120        0.0895             nan     0.1500   -0.0016
##    140        0.0607             nan     0.1500   -0.0011
##    160        0.0416             nan     0.1500   -0.0007
##    180        0.0285             nan     0.1500   -0.0005
##    200        0.0200             nan     0.1500   -0.0003
##    220        0.0141             nan     0.1500   -0.0003
##    240        0.0100             nan     0.1500   -0.0002
##    260        0.0071             nan     0.1500   -0.0002
##    280        0.0051             nan     0.1500   -0.0001
##    300        0.0037             nan     0.1500   -0.0001
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        3.0910             nan     0.1500    0.2830
##      2        2.6294             nan     0.1500    0.0996
##      3        2.4057             nan     0.1500    0.0786
##      4        2.2415             nan     0.1500    0.0235
##      5        2.1131             nan     0.1500    0.0295
##      6        1.9881             nan     0.1500    0.0598
##      7        1.8695             nan     0.1500    0.0074
##      8        1.7827             nan     0.1500    0.0209
##      9        1.6939             nan     0.1500    0.0009
##     10        1.6122             nan     0.1500   -0.0168
##     20        1.0747             nan     0.1500   -0.0246
##     40        0.5605             nan     0.1500   -0.0100
##     60        0.3229             nan     0.1500   -0.0045
##     80        0.1991             nan     0.1500   -0.0022
##    100        0.1290             nan     0.1500   -0.0027
##    120        0.0855             nan     0.1500   -0.0013
##    140        0.0581             nan     0.1500   -0.0012
##    160        0.0403             nan     0.1500   -0.0005
##    180        0.0280             nan     0.1500   -0.0006
##    200        0.0197             nan     0.1500   -0.0004
##    220        0.0139             nan     0.1500   -0.0002
##    240        0.0098             nan     0.1500   -0.0003
##    260        0.0071             nan     0.1500   -0.0002
##    280        0.0050             nan     0.1500   -0.0001
##    300        0.0036             nan     0.1500   -0.0001
## 
## Iter   TrainDeviance   ValidDeviance   StepSize   Improve
##      1        3.0910             nan     0.1500    0.1706
##      2        2.6863             nan     0.1500    0.1284
##      3        2.4730             nan     0.1500    0.0952
##      4        2.3051             nan     0.1500    0.0999
##      5        2.1551             nan     0.1500    0.0544
##      6        2.0367             nan     0.1500    0.0364
##      7        1.9257             nan     0.1500    0.0306
##      8        1.8264             nan     0.1500   -0.0012
##      9        1.7589             nan     0.1500    0.0294
##     10        1.6746             nan     0.1500    0.0200
##     20        1.1805             nan     0.1500   -0.0122
##     40        0.6785             nan     0.1500   -0.0083
##     60        0.4230             nan     0.1500   -0.0068
##     80        0.2747             nan     0.1500   -0.0039
##    100        0.1884             nan     0.1500   -0.0022
##    120        0.1321             nan     0.1500   -0.0011
##    140        0.0937             nan     0.1500   -0.0016
##    160        0.0685             nan     0.1500   -0.0009
##    180        0.0499             nan     0.1500   -0.0008
##    200        0.0372             nan     0.1500   -0.0007
##    220        0.0279             nan     0.1500   -0.0004
##    240        0.0209             nan     0.1500   -0.0004
##    260        0.0157             nan     0.1500   -0.0003
##    280        0.0119             nan     0.1500   -0.0002
##    300        0.0090             nan     0.1500   -0.0001</code></pre>
<pre class="r"><code>saveRDS(gbmFit_base,file = &#39;../lib/gbmFit_base.rds&#39;)</code></pre>
</div>
<div id="load-the-model." class="section level3">
<h3>Load the model.</h3>
<pre class="r"><code>gbmFit_base &lt;- readRDS(&#39;../lib/gbmFit_base.rds&#39;)</code></pre>
</div>
<div id="predict-the-data" class="section level3">
<h3>Predict the data</h3>
<pre class="r"><code>tm_train_base &lt;- system.time(pred0 &lt;- predict(gbmFit_base, newdata = dat_train))
tm_test_base &lt;- system.time(pred1 &lt;- predict(gbmFit_base, newdata = dat_test))

accu0 &lt;- mean(dat_train$emotion_idx == pred0)
accu1 &lt;- mean(dat_test$emotion_idx == pred1)

cat(&quot;The accuracy of model: gredient boosting on training set&quot;, &quot;is&quot;, accu0*100, &quot;%.\n&quot;)</code></pre>
<pre><code>## The accuracy of model: gredient boosting on training set is 100 %.</code></pre>
<pre class="r"><code>cat(&quot;The accuracy of model: gredient boosting on testing set&quot;, &quot;is&quot;, accu1*100, &quot;%.\n&quot;)</code></pre>
<pre><code>## The accuracy of model: gredient boosting on testing set is 43.2 %.</code></pre>
<pre class="r"><code>#confusionMatrix(pred1, dat_test$emotion_idx)</code></pre>
</div>
<div id="summarizing-running-time-for-base-model" class="section level3">
<h3>summarizing running time for base model</h3>
<pre class="r"><code>#cat(&quot;Time for building base model=&quot;, tm_train_gbm[1], &quot;s \n&quot;)
cat(&quot;Time for training base model=&quot;, tm_train_base[1], &quot;s \n&quot;)</code></pre>
<pre><code>## Time for training base model= 1.821 s</code></pre>
<pre class="r"><code>cat(&quot;Time for testing base model=&quot;, tm_test_base[1], &quot;s \n&quot;)</code></pre>
<pre><code>## Time for testing base model= 1.241 s</code></pre>
</div>
<div id="advanced-model" class="section level3">
<h3>advanced model</h3>
</div>
<div id="normalize-training-set-pca-on-training-set" class="section level3">
<h3>normalize training set &amp; PCA on training set</h3>
<pre class="r"><code># normalize
df_train_X &lt;- scale(dat_train[,!(names(dat_train) %in% &#39;emotion_idx&#39;)])
df_train_Y &lt;- dat_train$emotion_idx

# PCA on training
source(&#39;../lib/pca_feature.R&#39;)

pca &lt;- pca_feature(df_train_X,threshhold=0.99)

# combine PCA X, Y after PCA
pca_train &lt;- data.frame(pca$data_X_transformed,emotion_idx=df_train_Y)</code></pre>
</div>
<div id="build-advance-model-on-training" class="section level3">
<h3>build advance model on training</h3>
<pre class="r"><code>source(&#39;../lib/train_advance.R&#39;)

run.advance.train=TRUE
tm_advance_train=NA 

if(run.advance.train){
  tm_advance_lda2 &lt;- system.time(advance_model &lt;- train_advance(pca_train))
}</code></pre>
</div>
<div id="scale-on-test-transform-test-into-pc-dimensions" class="section level3">
<h3>scale on test &amp; transform test into PC dimensions</h3>
<pre class="r"><code>df_test_X &lt;- scale(dat_test[,!(names(dat_test) %in% &#39;emotion_idx&#39;)])
df_test_Y &lt;- dat_test$emotion_idx

data_test_X_transformed &lt;-  df_test_X  %*% pca$trans_matrix

# combine test X, Y after PCA
pca_test &lt;- data.frame(data_test_X_transformed,emotion_idx=df_test_Y)</code></pre>
</div>
<div id="predict-on-training-and-testing" class="section level3">
<h3>predict on training and testing</h3>
<pre class="r"><code>source(&#39;../lib/test_advance.R&#39;)


tm_advance_train &lt;- system.time(pred_train_advance &lt;- test_advance(model=advance_model,dat_pca_test=pca_train))

tm_advance_test &lt;- system.time(pred_test_advance &lt;- test_advance(model=advance_model,dat_pca_test=pca_test))


cat(&quot;The accuracy of advance model(lda2) on training set:&quot;,confusionMatrix(pred_train_advance,reference = pca_train$emotion_idx)$overall[1]*100, &quot;%.\n&quot;)</code></pre>
<pre><code>## The accuracy of advance model(lda2) on training set: 73.25 %.</code></pre>
<pre class="r"><code>cat(&quot;The accuracy of advance model(lda2) on testing set:&quot;,confusionMatrix(pred_test_advance,reference = pca_test$emotion_idx)$overall[1]*100, &quot;%.\n&quot;)</code></pre>
<pre><code>## The accuracy of advance model(lda2) on testing set: 50.8 %.</code></pre>
</div>
<div id="summarizing-running-time" class="section level3">
<h3>summarizing running time</h3>
<pre class="r"><code>cat(&quot;Time for building advance model=&quot;, tm_advance_lda2[1], &quot;s \n&quot;)</code></pre>
<pre><code>## Time for building advance model= 15.25 s</code></pre>
<pre class="r"><code>cat(&quot;Time for training advance model=&quot;, tm_advance_train[1], &quot;s \n&quot;)</code></pre>
<pre><code>## Time for training advance model= 0.031 s</code></pre>
<pre class="r"><code>cat(&quot;Time for testing advance model=&quot;, tm_advance_test[1], &quot;s \n&quot;)</code></pre>
<pre><code>## Time for testing advance model= 0.017 s</code></pre>
</div>




</div>

<script>

// add bootstrap table styles to pandoc tables
function bootstrapStylePandocTables() {
  $('tr.header').parent('thead').parent('table').addClass('table table-condensed');
}
$(document).ready(function () {
  bootstrapStylePandocTables();
});


</script>

<!-- tabsets -->

<script>
$(document).ready(function () {
  window.buildTabsets("TOC");
});

$(document).ready(function () {
  $('.tabset-dropdown > .nav-tabs > li').click(function () {
    $(this).parent().toggleClass('nav-tabs-open')
  });
});
</script>

<!-- code folding -->


<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
  (function () {
    var script = document.createElement("script");
    script.type = "text/javascript";
    script.src  = "https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-AMS-MML_HTMLorMML";
    document.getElementsByTagName("head")[0].appendChild(script);
  })();
</script>

</body>
</html>
