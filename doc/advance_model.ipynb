{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TO DO:\n",
    "\n",
    "- correct the path for the pipeline\n",
    "- correct the pathes\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.6/site-packages/sklearn/ensemble/weight_boosting.py:29: DeprecationWarning: numpy.core.umath_tests is an internal NumPy module and should not be imported. It will be removed in a future NumPy release.\n",
      "  from numpy.core.umath_tests import inner1d\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import time\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import scipy.io as sio\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage.feature import hog\n",
    "from skimage.transform import resize\n",
    "from skimage import data, exposure\n",
    "from PIL import Image\n",
    "from sklearn.svm import SVC #SVM classifier\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalize_and_flatten(features):\n",
    "    features = features - np.min(features, axis=0, keepdims=True)\n",
    "    features = features / np.max(features, axis=0, keepdims=True)\n",
    "    return features.flatten()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "resize_factor = (188, 250)\n",
    "\n",
    "train_img_path = '../data/train_set/train_images/'\n",
    "test_img_path = '../data/train_set/test_images/'\n",
    "train_features_path = '../data/train_set/train_points/'\n",
    "test_features_path = '../data/train_set/test_points/'\n",
    "labels = pd.read_csv('../data/train_set/label.csv')\n",
    "\n",
    "train_img = sorted(os.listdir(train_img_path))\n",
    "test_img = sorted(os.listdir(test_img_path))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TRUE Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Train emotion indexes\n",
    "train_indexes = []\n",
    "for img in train_img:\n",
    "    if img == \".DS_Store\":\n",
    "        continue\n",
    "    img = int(img[:4])\n",
    "    train_indexes.append(img - 1)\n",
    "    \n",
    "emotion_idx = labels[['emotion_idx']].loc[train_indexes].values[:, 0]\n",
    "\n",
    "### Test emotion indexes\n",
    "test_indexes = []\n",
    "for img in test_img:\n",
    "    if img == \".DS_Store\":\n",
    "        continue\n",
    "    img = int(img[:4])\n",
    "    test_indexes.append(img - 1)\n",
    "    \n",
    "test_emotion_idx = labels[['emotion_idx']].loc[test_indexes].values[:, 0]   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## FEATURES\n",
    "#### HOGS, train_features, concat_train_features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 122.83936095237732 seconds ---\n",
      "--- 30.634644985198975 seconds ---\n"
     ]
    }
   ],
   "source": [
    "### extract HOG for train data set\n",
    "\n",
    "HOGs = []\n",
    "start_time = time.time()\n",
    "for img in train_img:\n",
    "    if img == '.DS_Store':\n",
    "        continue\n",
    "    img = np.asarray(Image.open(os.path.join(train_img_path, img)))\n",
    "    img = resize(img, resize_factor, anti_aliasing=False)\n",
    "    fetures_hog = hog(img, orientations=9, pixels_per_cell=(8, 8),\n",
    "                    cells_per_block=(3, 3), visualize=False, multichannel=True)\n",
    "    HOGs.append(fetures_hog)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))  \n",
    "\n",
    "### extract HOG for test data set\n",
    "\n",
    "HOGs_test = []\n",
    "start_time = time.time()\n",
    "for img in test_img:\n",
    "    if img == '.DS_Store':\n",
    "        continue\n",
    "    img = np.asarray(Image.open(os.path.join('../data/train_set/test_images/', img)))\n",
    "    img = resize(img, resize_factor, anti_aliasing=False)\n",
    "    fetures_hog = hog(img, orientations=9, pixels_per_cell=(8, 8),\n",
    "                    cells_per_block=(3, 3), visualize=False, multichannel=True)\n",
    "    HOGs_test.append(fetures_hog)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time)) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "### Point features for train dataset (NORMALIZED VERSION)\n",
    "train_features = sorted(os.listdir(train_features_path))\n",
    "train_features_list = []\n",
    "for f in train_features:\n",
    "    tmp = sio.loadmat(os.path.join(train_features_path, f))\n",
    "    if 'faceCoordinatesUnwarped' in tmp:\n",
    "        features = tmp['faceCoordinatesUnwarped']\n",
    "    else:\n",
    "        features = tmp['faceCoordinates2']\n",
    "    train_features_list.append(normalize_and_flatten(features))\n",
    "    \n",
    "### Point features for test dataset (NORMALIZED VERSION)\n",
    "test_features = sorted(os.listdir(test_features_path))\n",
    "test_features_list = []\n",
    "for f in test_features:\n",
    "    tmp = sio.loadmat(os.path.join(test_features_path, f))\n",
    "    if 'faceCoordinatesUnwarped' in tmp:\n",
    "        features = tmp['faceCoordinatesUnwarped']\n",
    "    else:\n",
    "        features = tmp['faceCoordinates2']\n",
    "    test_features_list.append(normalize_and_flatten(features))    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- 14.114684820175171 seconds ---\n",
      "--- 1.072826862335205 seconds ---\n"
     ]
    }
   ],
   "source": [
    "### Cancate of HOG and .mat features train\n",
    "start_time = time.time()\n",
    "pca = PCA(n_components=100)\n",
    "reduced_hogs = pca.fit_transform(np.array(HOGs)) \n",
    "train_np = np.array(train_features_list)\n",
    "concat_train_features = np.concatenate((reduced_hogs, train_np), axis=1)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))\n",
    "\n",
    "### test\n",
    "start_time = time.time()\n",
    "reduced_hogs_test = pca.transform(np.array(HOGs_test))\n",
    "test_np = np.array(test_features_list)\n",
    "concat_test_features = np.concatenate((reduced_hogs_test, test_np), axis=1)\n",
    "print(\"--- %s seconds ---\" % (time.time() - start_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CLASSIFIERS"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM on HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Duration : 483.01157999038696 seconds\n",
      "Train Accuracy Durtion: 259.4689209461212 seconds\n",
      "Train Accuracy: 0.09404702351175588\n",
      "Test Accuracy Duration: 68.76027393341064 seconds\n",
      "Test Accuracy: 0.06786427145708583\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "linear_SVM = SVC(kernel=\"linear\", C=0.001)\n",
    "linear_SVM.fit(np.array(HOGs), emotion_idx)\n",
    "print(\"Train Duration : %s seconds\" % (time.time() - start_time)) \n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = linear_SVM.score(np.array(HOGs), emotion_idx)\n",
    "print(\"Train Accuracy Durtion: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Train Accuracy: {}\".format(accuracy))\n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = linear_SVM.score(np.array(HOGs_test), test_emotion_idx)\n",
    "print(\"Test Accuracy Duration: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Test Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Linear SVM on .mat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Duration : 1.283754825592041 seconds\n",
      "Train Accuracy Durtion: 0.7464189529418945 seconds\n",
      "Train Accuracy: 0.05202601300650325\n",
      "Test Accuracy Duration: 0.19126558303833008 seconds\n",
      "Test Accuracy: 0.06187624750499002\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "linear_SVM = SVC(kernel=\"linear\", C=0.001)\n",
    "linear_SVM.fit(np.array(train_features_list), emotion_idx)\n",
    "print(\"Train Duration : %s seconds\" % (time.time() - start_time)) \n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = linear_SVM.score(np.array(train_features_list), emotion_idx)\n",
    "print(\"Train Accuracy Durtion: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Train Accuracy: {}\".format(accuracy))\n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = linear_SVM.score(np.array(test_features_list), test_emotion_idx)\n",
    "print(\"Test Accuracy Duration: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Test Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L SVM on concat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Duration : 2.1608119010925293 seconds\n",
      "Train Accuracy Durtion: 1.254235029220581 seconds\n",
      "Train Accuracy: 0.07253626813406704\n",
      "Test Accuracy Duration: 0.31401801109313965 seconds\n",
      "Test Accuracy: 0.0658682634730539\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "linear_SVM = SVC(kernel=\"linear\", C=0.001)\n",
    "linear_SVM.fit(concat_train_features, emotion_idx)\n",
    "print(\"Train Duration : %s seconds\" % (time.time() - start_time)) \n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = linear_SVM.score(concat_train_features, emotion_idx)\n",
    "print(\"Train Accuracy Durtion: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Train Accuracy: {}\".format(accuracy))\n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = linear_SVM.score(concat_test_features, test_emotion_idx)\n",
    "print(\"Test Accuracy Duration: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Test Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### L SVM on PCA HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Duration : 16.768794059753418 seconds\n",
      "Train Accuracy Durtion: 1.0205650329589844 seconds\n",
      "Train Accuracy: 0.39919959979989994\n",
      "Test Accuracy Duration: 0.7323682308197021 seconds\n",
      "Test Accuracy: 0.09580838323353294\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "pca = PCA(n_components=200)\n",
    "reduced_features = pca.fit_transform(np.array(HOGs))\n",
    "linear_SVM = SVC(kernel=\"linear\", C=0.01)\n",
    "linear_SVM.fit(reduced_features, emotion_idx)\n",
    "print(\"Train Duration : %s seconds\" % (time.time() - start_time)) \n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = linear_SVM.score(reduced_features, emotion_idx)\n",
    "print(\"Train Accuracy Durtion: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Train Accuracy: {}\".format(accuracy))\n",
    "\n",
    "start_time = time.time()\n",
    "reduced_test = pca.transform(np.array(HOGs_test))\n",
    "accuracy = linear_SVM.score(reduced_test, test_emotion_idx)\n",
    "print(\"Test Accuracy Duration: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Test Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM on PCA HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Duration : 15.348134279251099 seconds\n",
      "Train Accuracy Durtion: 0.5401968955993652 seconds\n",
      "Train Accuracy: 0.9934967483741871\n",
      "Test Accuracy Duration: 0.5810391902923584 seconds\n",
      "Test Accuracy: 0.04590818363273453\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "pca = PCA(n_components=100)\n",
    "reduced_features = pca.fit_transform(np.array(HOGs))\n",
    "model = SVC(gamma='auto', C=10)\n",
    "model.fit(reduced_features, emotion_idx)\n",
    "print(\"Train Duration : %s seconds\" % (time.time() - start_time)) \n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = model.score(reduced_features, emotion_idx)\n",
    "print(\"Train Accuracy Durtion: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Train Accuracy: {}\".format(accuracy))\n",
    "\n",
    "start_time = time.time()\n",
    "reduced_test = pca.transform(np.array(HOGs_test))\n",
    "accuracy = model.score(reduced_test, test_emotion_idx)\n",
    "print(\"Test Accuracy Duration: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Test Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM on .mat Features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Duration : 0.7238380908966064 seconds\n",
      "Train Accuracy Durtion: 0.8284599781036377 seconds\n",
      "Train Accuracy: 0.6183091545772886\n",
      "Test Accuracy Duration: 0.1888411045074463 seconds\n",
      "Test Accuracy: 0.46506986027944114\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = SVC(gamma='auto', C=1000)\n",
    "model.fit(np.array(train_features_list), emotion_idx)\n",
    "print(\"Train Duration : %s seconds\" % (time.time() - start_time)) \n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = model.score(np.array(train_features_list), emotion_idx)\n",
    "print(\"Train Accuracy Durtion: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Train Accuracy: {}\".format(accuracy))\n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = model.score(np.array(test_features_list), test_emotion_idx)\n",
    "print(\"Test Accuracy Duration: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Test Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### SVM on concat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Duration : 2.657891035079956 seconds\n",
      "Train Accuracy Durtion: 1.3531501293182373 seconds\n",
      "Train Accuracy: 0.8539269634817409\n",
      "Test Accuracy Duration: 0.36635494232177734 seconds\n",
      "Test Accuracy: 0.07584830339321358\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = SVC(gamma='auto', C=10)\n",
    "model.fit(concat_train_features, emotion_idx)\n",
    "print(\"Train Duration : %s seconds\" % (time.time() - start_time)) \n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = model.score(concat_train_features, emotion_idx)\n",
    "print(\"Train Accuracy Durtion: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Train Accuracy: {}\".format(accuracy))\n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = model.score(concat_test_features, test_emotion_idx)\n",
    "print(\"Test Accuracy Duration: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Test Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RandomForestClassifier on PCA HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Duration : 11.663228273391724 seconds\n",
      "Train Accuracy Durtion: 0.02125692367553711 seconds\n",
      "Train Accuracy: 0.5317658829414708\n",
      "Test Accuracy Duration: 0.337507963180542 seconds\n",
      "Test Accuracy: 0.06187624750499002\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "pca = PCA(n_components=100)\n",
    "reduced_features = pca.fit_transform(np.array(HOGs))\n",
    "model = RandomForestClassifier(max_depth=5, n_estimators=50)\n",
    "model.fit(reduced_features, emotion_idx)\n",
    "print(\"Train Duration : %s seconds\" % (time.time() - start_time)) \n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = model.score(reduced_features, emotion_idx)\n",
    "print(\"Train Accuracy Durtion: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Train Accuracy: {}\".format(accuracy))\n",
    "\n",
    "start_time = time.time()\n",
    "reduced_test = pca.transform(np.array(HOGs_test))\n",
    "accuracy = model.score(reduced_test, test_emotion_idx)\n",
    "print(\"Test Accuracy Duration: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Test Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFC on .mat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Duration : 1.1041409969329834 seconds\n",
      "Train Accuracy Durtion: 0.030183076858520508 seconds\n",
      "Train Accuracy: 0.5157578789394698\n",
      "Test Accuracy Duration: 0.011514902114868164 seconds\n",
      "Test Accuracy: 0.3013972055888224\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = RandomForestClassifier(max_depth=5, n_estimators=100)\n",
    "model.fit(np.array(train_features_list), emotion_idx)\n",
    "print(\"Train Duration : %s seconds\" % (time.time() - start_time)) \n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = model.score(np.array(train_features_list), emotion_idx)\n",
    "print(\"Train Accuracy Durtion: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Train Accuracy: {}\".format(accuracy))\n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = model.score(np.array(test_features_list), test_emotion_idx)\n",
    "print(\"Test Accuracy Duration: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Test Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### RFC on cancate features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Duration : 1.3742477893829346 seconds\n",
      "Train Accuracy Durtion: 0.05086398124694824 seconds\n",
      "Train Accuracy: 0.5327663831915957\n",
      "Test Accuracy Duration: 0.025084972381591797 seconds\n",
      "Test Accuracy: 0.3073852295409182\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = RandomForestClassifier(max_depth=5, n_estimators=100)\n",
    "model.fit(concat_train_features, emotion_idx)\n",
    "print(\"Train Duration : %s seconds\" % (time.time() - start_time)) \n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = model.score(concat_train_features, emotion_idx)\n",
    "print(\"Train Accuracy Durtion: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Train Accuracy: {}\".format(accuracy))\n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = model.score(concat_test_features, test_emotion_idx)\n",
    "print(\"Test Accuracy Duration: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Test Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLPClassifier on pca HOG"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Duration : 19.290612936019897 seconds\n",
      "Train Accuracy Durtion: 0.04608917236328125 seconds\n",
      "Train Accuracy: 0.9904952476238119\n",
      "Test Accuracy Duration: 0.9957513809204102 seconds\n",
      "Test Accuracy: 0.08183632734530938\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "pca = PCA(n_components=100)\n",
    "reduced_features = pca.fit_transform(np.array(HOGs))\n",
    "model = MLPClassifier(hidden_layer_sizes=(300, 600, 300, 150, 60, 40))\n",
    "model.fit(reduced_features, emotion_idx)\n",
    "print(\"Train Duration : %s seconds\" % (time.time() - start_time)) \n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = model.score(reduced_features, emotion_idx)\n",
    "print(\"Train Accuracy Durtion: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Train Accuracy: {}\".format(accuracy))\n",
    "\n",
    "start_time = time.time()\n",
    "reduced_test = pca.transform(np.array(HOGs_test))\n",
    "accuracy = model.score(reduced_test, test_emotion_idx)\n",
    "print(\"Test Accuracy Duration: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Test Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP on .mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Duration : 3.587941884994507 seconds\n",
      "Train Accuracy Durtion: 0.0499267578125 seconds\n",
      "Train Accuracy: 0.1265632816408204\n",
      "Test Accuracy Duration: 0.011600971221923828 seconds\n",
      "Test Accuracy: 0.10778443113772455\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = MLPClassifier(hidden_layer_sizes=(300, 600, 300, 150, 60, 40))\n",
    "model.fit(np.array(train_features_list), emotion_idx)\n",
    "print(\"Train Duration : %s seconds\" % (time.time() - start_time)) \n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = model.score(np.array(train_features_list), emotion_idx)\n",
    "print(\"Train Accuracy Durtion: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Train Accuracy: {}\".format(accuracy))\n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = model.score(np.array(test_features_list), test_emotion_idx)\n",
    "print(\"Test Accuracy Duration: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Test Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### MLP on concat features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Duration : 5.981200933456421 seconds\n",
      "Train Accuracy Durtion: 0.04111790657043457 seconds\n",
      "Train Accuracy: 0.9959979989994997\n",
      "Test Accuracy Duration: 0.010310888290405273 seconds\n",
      "Test Accuracy: 0.11976047904191617\n"
     ]
    }
   ],
   "source": [
    "start_time = time.time()\n",
    "model = MLPClassifier(hidden_layer_sizes=(300, 600, 300, 60, 40))\n",
    "model.fit(concat_train_features, emotion_idx)\n",
    "print(\"Train Duration : %s seconds\" % (time.time() - start_time)) \n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = model.score(concat_train_features, emotion_idx)\n",
    "print(\"Train Accuracy Durtion: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Train Accuracy: {}\".format(accuracy))\n",
    "\n",
    "start_time = time.time()\n",
    "accuracy = model.score(concat_test_features, test_emotion_idx)\n",
    "print(\"Test Accuracy Duration: %s seconds\" % (time.time() - start_time)) \n",
    "print(\"Test Accuracy: {}\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
